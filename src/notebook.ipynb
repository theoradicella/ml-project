{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¾ UCI Adult Dataset - Machine Learning Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This machine learning project, conducted under the guidance of Professor Matteo Zignani from UniversitÃ  degli Studi di Milano, focuses on a supervised binary classification task using the Adult dataset. The dataset, originally from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult), is typically provided pre-split into training and test sets. To have greater control over the data splitting process, we used a [version of the dataset available on Kaggle](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset), which provides the data in a single, unsplit format. This approach allowed us to perform our own train-test split.\n",
    "\n",
    "The goal of the project is to classify whether an individual earns more than $50,000 per year by leveraging preprocessing techniques and classification models to uncover patterns and relationships within the data, ultimately building an accurate predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Perceptron\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Custom utils\n",
    "from utils.constants import country_mapping\n",
    "from utils.configs import sampler_configs, dim_reduction_configs, classifier_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training set into a Pandas dataframe and look more into detail the different columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/adult.csv\", header=0, skipinitialspace=True, na_values=\"?\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        46043 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       46033 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   47985 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some columns have null values, let's look into more detail which ones and how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          2799\n",
       "fnlwgt                0\n",
       "education             0\n",
       "educational-num       0\n",
       "marital-status        0\n",
       "occupation         2809\n",
       "relationship          0\n",
       "race                  0\n",
       "gender                0\n",
       "capital-gain          0\n",
       "capital-loss          0\n",
       "hours-per-week        0\n",
       "native-country      857\n",
       "income                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to deal with missing values for the columns `workclass`, `occupation` and `native-country`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some example rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n",
      "Private             33906\n",
      "Self-emp-not-inc     3862\n",
      "Local-gov            3136\n",
      "State-gov            1981\n",
      "Self-emp-inc         1695\n",
      "Federal-gov          1432\n",
      "Without-pay            21\n",
      "Never-worked           10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Change 'race' for any other feature you'd like to inspect.\n",
    "print(df['workclass'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Data Transformation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a schema of the data transformation pipeline that we want to create. The columns that are not present are going to be dropped.\n",
    "\n",
    "![Data transformatino Pipeline](./images/data-transformation-pipeline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we utilize five custom transformers to handle specific feature engineering tasks. These transformers ensure that our preprocessing pipeline remains clean, modular, and reusable.\n",
    "\n",
    "Below is an explanation of each custom transformer and their purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers in the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we are going to use 4 different custom transformer for some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. `MaritalStatusBinarizer`\n",
    "\n",
    "Converts the **marital-status** feature into a binary feature (1 for married, 0 for not married) to simplify analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_marital_status(X):\n",
    "    mapping = {\n",
    "        'Married-civ-spouse': 1,\n",
    "        'Married-spouse-absent': 1,\n",
    "        'Married-AF-spouse': 1,\n",
    "        'Never-married': 0,\n",
    "        'Divorced': 0,\n",
    "        'Separated': 0,\n",
    "        'Widowed': 0\n",
    "    }\n",
    "\n",
    "    # Convert dataframe to numpy array\n",
    "    X = X.values.ravel()\n",
    "\n",
    "    return np.array([[mapping.get(value, 0)] for value in X])\n",
    "\n",
    "# Pipeline for Marital Status\n",
    "pipeline_marital_status = Pipeline([\n",
    "    ('marital-status-binarizer', FunctionTransformer(binarize_marital_status,\n",
    "    validate=False,\n",
    "))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `CombineCapitalFeatures`\n",
    "\n",
    "Combines the **capital-gain** and **capital-loss** features into a single **net-capital** feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineCapitalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert X into a NumPy array\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        # Compute net-capital (difference between gain and loss)\n",
    "        net_capital = X[:, 0] - X[:, 1]\n",
    "        \n",
    "        # Return as a 2D array (Scikit-learn expects this format)\n",
    "        return net_capital.reshape(-1, 1)\n",
    "\n",
    "# Pipeline for combining and scaling capital features\n",
    "pipeline_capital_features = Pipeline([\n",
    "    ('combine_capital', CombineCapitalFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. `HoursBinner`\n",
    "\n",
    "Bins the **hours-per-week** feature into categories: Part-time, Full-time, and Overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoursBinner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.Series(X.values.ravel())\n",
    "        \n",
    "        # Define bins and labels\n",
    "        bins = [0, 30, 50, float('inf')]  # Inf handles any hours > 50\n",
    "        labels = ['Part-time', 'Full-time', 'Overtime']\n",
    "        \n",
    "        # Apply binning\n",
    "        binned = pd.cut(X, bins=bins, labels=labels, right=False)\n",
    "        \n",
    "        # Return as a 2D array\n",
    "        return np.array(binned).reshape(-1, 1)\n",
    "\n",
    "# Pipeline for Hours Binning\n",
    "pipeline_hours_binner = Pipeline([\n",
    "    ('binning', HoursBinner()),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. `CountryGrouper`\n",
    "\n",
    "Groups the **native-country** feature into broader regions (e.g., North America, Europe) to reduce the number of categories and simplify the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryGrouper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Flatten X to a 1D array for processing\n",
    "        X_flat = np.ravel(X)\n",
    "\n",
    "        # Apply mapping with a default value of \"Other\" for unknown countries\n",
    "        grouped = [country_mapping.get(country, 'Other') for country in X_flat]\n",
    "\n",
    "        # Return as a 2D array\n",
    "        return np.array(grouped).reshape(-1, 1)\n",
    "\n",
    "# Pipeline for Country Grouping and Encoding\n",
    "pipeline_country = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('group', CountryGrouper()),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish by creating the pipelines for the remaining features that have more than one transformation and defining the Column Transformer for **all** the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines for the remaning features\n",
    "pipeline_workclass_occupation = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine all pipelines in a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('scaler', StandardScaler(), ['age', 'educational-num']),\n",
    "    ('workclass_occupation', pipeline_workclass_occupation, ['workclass', 'occupation']),\n",
    "    ('marital_status', pipeline_marital_status, ['marital-status']),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['relationship', 'race', 'gender']),\n",
    "    ('capital', pipeline_capital_features, ['capital-gain', 'capital-loss']),\n",
    "    ('hours_per_week', pipeline_hours_binner, ['hours-per-week']),\n",
    "    ('native_country', pipeline_country, ['native-country']),\n",
    "],\n",
    "remainder='drop',\n",
    "verbose_feature_names_out=False,\n",
    "sparse_threshold=0) # Dense matrices instead of sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can split the entire dataset into training and test sets, putting 20% of the instances in the test set. We will first binarize the income into 0/1 values for better readibility, yada yada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "df['income'] = lb.fit_transform(df['income']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base pipeline\n",
    "model_pipeline = IMBPipeline([  #IMB(alanced) pipeline allow us to add sampler configs\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('dim_reduction', PCA(n_components=0.8)),\n",
    "    ('classifier', Perceptron())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configurations: 30\n"
     ]
    }
   ],
   "source": [
    "# Combine all configurations\n",
    "import itertools\n",
    "\n",
    "all_configs = [\n",
    "    dict(itertools.chain(*(config.items() for config in combination)))\n",
    "    for combination in itertools.product(sampler_configs, dim_reduction_configs, classifier_configs)\n",
    "]\n",
    "\n",
    "print(f\"Number of configurations: {len(all_configs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(\n",
    "    model_pipeline,\n",
    "    param_distributions=all_configs,\n",
    "    n_iter=50,  # Adjust the number of iterations\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "# Inspect the best configuration\n",
    "print(\"Best Params:\", rs.best_params_)\n",
    "print(\"Best F1 Score:\", rs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outer loop with cross-validation\n",
    "scores = cross_validate(\n",
    "    rs,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "# Inspect results\n",
    "for index, estimator in enumerate(scores['estimator']):\n",
    "    print(f\"Fold {index + 1}:\")\n",
    "    print(\"Sampler:\", estimator.best_estimator_.get_params()['sampler'])\n",
    "    print(\"Dim Reduction:\", estimator.best_estimator_.get_params()['dim_reduction'])\n",
    "    print(\"Classifier:\", estimator.best_estimator_.get_params()['classifier'])\n",
    "    print(\"Validation F1:\", scores['test_score'][index])\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on training set: 0.718\n",
      "F1 on test set: 0.676\n",
      "----------\n",
      "F1 on training set: 0.718\n",
      "F1 on test set: 0.679\n",
      "----------\n",
      "F1 on training set: 0.716\n",
      "F1 on test set: 0.677\n",
      "----------\n",
      "F1 on training set: 0.717\n",
      "F1 on test set: 0.681\n",
      "----------\n",
      "F1 on training set: 0.716\n",
      "F1 on test set: 0.676\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for estimator in scores['estimator']:\n",
    "    best_model = estimator.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    train_pred = best_model.predict(X_train)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # F1 Scores\n",
    "    f1_train = f1_score(y_train, train_pred)\n",
    "    f1_test = f1_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"F1 on training set: {f1_train:.3f}\")\n",
    "    print(f\"F1 on test set: {f1_test:.3f}\")\n",
    "    print('-' * 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
